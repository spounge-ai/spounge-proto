// @generated by protoc-gen-es v2.6.0 with parameter "target=ts,import_extension=none"
// @generated from file llm/v2/llm.proto (package llm.v2, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv2";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv2";
import type { Metadata, Status } from "../../common/v2/common_pb";
import { file_common_v2_common } from "../../common/v2/common_pb";
import { file_google_protobuf_struct } from "@bufbuild/protobuf/wkt";
import type { JsonObject, Message as Message$1 } from "@bufbuild/protobuf";

/**
 * Describes the file llm/v2/llm.proto.
 */
export const file_llm_v2_llm: GenFile = /*@__PURE__*/
  fileDesc("ChBsbG0vdjIvbGxtLnByb3RvEgZsbG0udjIiWQoHTWVzc2FnZRIhCgRyb2xlGAEgASgOMhMubGxtLnYyLk1lc3NhZ2VSb2xlEg8KB2NvbnRlbnQYAiABKAkSEQoEbmFtZRgDIAEoCUgAiAEBQgcKBV9uYW1lIlYKBFRvb2wSDAoEbmFtZRgBIAEoCRITCgtkZXNjcmlwdGlvbhgCIAEoCRIrCgpwYXJhbWV0ZXJzGAMgASgLMhcuZ29vZ2xlLnByb3RvYnVmLlN0cnVjdCI3CghUb29sQ2FsbBIKCgJpZBgBIAEoCRIMCgRuYW1lGAIgASgJEhEKCWFyZ3VtZW50cxgDIAEoCSK6AQoQR2VuZXJhdGlvblBhcmFtcxIYCgt0ZW1wZXJhdHVyZRgBIAEoAkgAiAEBEhIKBXRvcF9wGAIgASgCSAGIAQESFwoKbWF4X3Rva2VucxgDIAEoBUgCiAEBEhYKDnN0b3Bfc2VxdWVuY2VzGAQgAygJEhMKBnN0cmVhbRgFIAEoCEgDiAEBQg4KDF90ZW1wZXJhdHVyZUIICgZfdG9wX3BCDQoLX21heF90b2tlbnNCCQoHX3N0cmVhbSJUCgpUb2tlblVzYWdlEhUKDXByb21wdF90b2tlbnMYASABKAUSGQoRY29tcGxldGlvbl90b2tlbnMYAiABKAUSFAoMdG90YWxfdG9rZW5zGAMgASgFIukBChNHZW5lcmF0ZVRleHRSZXF1ZXN0EiIKCHByb3ZpZGVyGAEgASgOMhAubGxtLnYyLlByb3ZpZGVyEg0KBW1vZGVsGAIgASgJEiEKCG1lc3NhZ2VzGAMgAygLMg8ubGxtLnYyLk1lc3NhZ2USLQoGcGFyYW1zGAQgASgLMhgubGxtLnYyLkdlbmVyYXRpb25QYXJhbXNIAIgBARIbCgV0b29scxgFIAMoCzIMLmxsbS52Mi5Ub29sEiUKCG1ldGFkYXRhGAYgASgLMhMuY29tbW9uLnYyLk1ldGFkYXRhQgkKB19wYXJhbXMi0wEKFEdlbmVyYXRlVGV4dFJlc3BvbnNlEiEKBnN0YXR1cxgBIAEoCzIRLmNvbW1vbi52Mi5TdGF0dXMSKQoQcmVzcG9uc2VfbWVzc2FnZRgCIAEoCzIPLmxsbS52Mi5NZXNzYWdlEiQKCnRvb2xfY2FsbHMYAyADKAsyEC5sbG0udjIuVG9vbENhbGwSJgoFdXNhZ2UYBCABKAsyEi5sbG0udjIuVG9rZW5Vc2FnZUgAiAEBEhUKDWZpbmlzaF9yZWFzb24YBSABKAlCCAoGX3VzYWdlIkkKGUdlbmVyYXRlVGV4dFN0cmVhbVJlcXVlc3QSLAoHcmVxdWVzdBgBIAEoCzIbLmxsbS52Mi5HZW5lcmF0ZVRleHRSZXF1ZXN0IsABChpHZW5lcmF0ZVRleHRTdHJlYW1SZXNwb25zZRIhCgZzdGF0dXMYASABKAsyES5jb21tb24udjIuU3RhdHVzEg0KBWRlbHRhGAIgASgJEiYKBXVzYWdlGAMgASgLMhIubGxtLnYyLlRva2VuVXNhZ2VIAIgBARIaCg1maW5pc2hfcmVhc29uGAQgASgJSAGIAQESEAoIaXNfZmluYWwYBSABKAhCCAoGX3VzYWdlQhAKDl9maW5pc2hfcmVhc29uIoMBChhHZW5lcmF0ZUVtYmVkZGluZ1JlcXVlc3QSIgoIcHJvdmlkZXIYASABKA4yEC5sbG0udjIuUHJvdmlkZXISDQoFbW9kZWwYAiABKAkSDQoFdGV4dHMYAyADKAkSJQoIbWV0YWRhdGEYBCABKAsyEy5jb21tb24udjIuTWV0YWRhdGEiLgoJRW1iZWRkaW5nEg4KBnZhbHVlcxgBIAMoAhIRCglkaW1lbnNpb24YAiABKAUilwEKGUdlbmVyYXRlRW1iZWRkaW5nUmVzcG9uc2USIQoGc3RhdHVzGAEgASgLMhEuY29tbW9uLnYyLlN0YXR1cxIlCgplbWJlZGRpbmdzGAIgAygLMhEubGxtLnYyLkVtYmVkZGluZxImCgV1c2FnZRgDIAEoCzISLmxsbS52Mi5Ub2tlblVzYWdlSACIAQFCCAoGX3VzYWdlKqsBCghQcm92aWRlchIYChRQUk9WSURFUl9VTlNQRUNJRklFRBAAEhMKD1BST1ZJREVSX09QRU5BSRABEhYKElBST1ZJREVSX0FOVEhST1BJQxACEhMKD1BST1ZJREVSX0dPT0dMRRADEhkKFVBST1ZJREVSX0FaVVJFX09QRU5BSRAEEhMKD1BST1ZJREVSX0NPSEVSRRAFEhMKD1BST1ZJREVSX09MTEFNQRAGKo4BCgtNZXNzYWdlUm9sZRIcChhNRVNTQUdFX1JPTEVfVU5TUEVDSUZJRUQQABIXChNNRVNTQUdFX1JPTEVfU1lTVEVNEAESFQoRTUVTU0FHRV9ST0xFX1VTRVIQAhIaChZNRVNTQUdFX1JPTEVfQVNTSVNUQU5UEAMSFQoRTUVTU0FHRV9ST0xFX1RPT0wQBDKeAgoSTExNUHJvdmlkZXJTZXJ2aWNlEksKDEdlbmVyYXRlVGV4dBIbLmxsbS52Mi5HZW5lcmF0ZVRleHRSZXF1ZXN0GhwubGxtLnYyLkdlbmVyYXRlVGV4dFJlc3BvbnNlIgASXwoSR2VuZXJhdGVUZXh0U3RyZWFtEiEubGxtLnYyLkdlbmVyYXRlVGV4dFN0cmVhbVJlcXVlc3QaIi5sbG0udjIuR2VuZXJhdGVUZXh0U3RyZWFtUmVzcG9uc2UiADABEloKEUdlbmVyYXRlRW1iZWRkaW5nEiAubGxtLnYyLkdlbmVyYXRlRW1iZWRkaW5nUmVxdWVzdBohLmxsbS52Mi5HZW5lcmF0ZUVtYmVkZGluZ1Jlc3BvbnNlIgBCiQEKCmNvbS5sbG0udjJCCExsbVByb3RvUAFaOGdpdGh1Yi5jb20vc3BvdW5nZS1haS9zcG91bmdlLXByb3Rvcy9nZW4vZ28vbGxtL3YyO2xsbXYyogIDTFhYqgIGTGxtLlYyygIGTGxtXFYy4gISTGxtXFYyXEdQQk1ldGFkYXRh6gIHTGxtOjpWMmIGcHJvdG8z", [file_common_v2_common, file_google_protobuf_struct]);

/**
 * @generated from message llm.v2.Message
 */
export type Message = Message$1<"llm.v2.Message"> & {
  /**
   * @generated from field: llm.v2.MessageRole role = 1;
   */
  role: MessageRole;

  /**
   * @generated from field: string content = 2;
   */
  content: string;

  /**
   * @generated from field: optional string name = 3;
   */
  name?: string;
};

/**
 * Describes the message llm.v2.Message.
 * Use `create(MessageSchema)` to create a new message.
 */
export const MessageSchema: GenMessage<Message> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 0);

/**
 * @generated from message llm.v2.Tool
 */
export type Tool = Message$1<"llm.v2.Tool"> & {
  /**
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * @generated from field: string description = 2;
   */
  description: string;

  /**
   * @generated from field: google.protobuf.Struct parameters = 3;
   */
  parameters?: JsonObject;
};

/**
 * Describes the message llm.v2.Tool.
 * Use `create(ToolSchema)` to create a new message.
 */
export const ToolSchema: GenMessage<Tool> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 1);

/**
 * @generated from message llm.v2.ToolCall
 */
export type ToolCall = Message$1<"llm.v2.ToolCall"> & {
  /**
   * @generated from field: string id = 1;
   */
  id: string;

  /**
   * @generated from field: string name = 2;
   */
  name: string;

  /**
   * @generated from field: string arguments = 3;
   */
  arguments: string;
};

/**
 * Describes the message llm.v2.ToolCall.
 * Use `create(ToolCallSchema)` to create a new message.
 */
export const ToolCallSchema: GenMessage<ToolCall> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 2);

/**
 * @generated from message llm.v2.GenerationParams
 */
export type GenerationParams = Message$1<"llm.v2.GenerationParams"> & {
  /**
   * @generated from field: optional float temperature = 1;
   */
  temperature?: number;

  /**
   * @generated from field: optional float top_p = 2;
   */
  topP?: number;

  /**
   * @generated from field: optional int32 max_tokens = 3;
   */
  maxTokens?: number;

  /**
   * @generated from field: repeated string stop_sequences = 4;
   */
  stopSequences: string[];

  /**
   * @generated from field: optional bool stream = 5;
   */
  stream?: boolean;
};

/**
 * Describes the message llm.v2.GenerationParams.
 * Use `create(GenerationParamsSchema)` to create a new message.
 */
export const GenerationParamsSchema: GenMessage<GenerationParams> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 3);

/**
 * @generated from message llm.v2.TokenUsage
 */
export type TokenUsage = Message$1<"llm.v2.TokenUsage"> & {
  /**
   * @generated from field: int32 prompt_tokens = 1;
   */
  promptTokens: number;

  /**
   * @generated from field: int32 completion_tokens = 2;
   */
  completionTokens: number;

  /**
   * @generated from field: int32 total_tokens = 3;
   */
  totalTokens: number;
};

/**
 * Describes the message llm.v2.TokenUsage.
 * Use `create(TokenUsageSchema)` to create a new message.
 */
export const TokenUsageSchema: GenMessage<TokenUsage> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 4);

/**
 * @generated from message llm.v2.GenerateTextRequest
 */
export type GenerateTextRequest = Message$1<"llm.v2.GenerateTextRequest"> & {
  /**
   * @generated from field: llm.v2.Provider provider = 1;
   */
  provider: Provider;

  /**
   * @generated from field: string model = 2;
   */
  model: string;

  /**
   * @generated from field: repeated llm.v2.Message messages = 3;
   */
  messages: Message[];

  /**
   * @generated from field: optional llm.v2.GenerationParams params = 4;
   */
  params?: GenerationParams;

  /**
   * @generated from field: repeated llm.v2.Tool tools = 5;
   */
  tools: Tool[];

  /**
   * @generated from field: common.v2.Metadata metadata = 6;
   */
  metadata?: Metadata;
};

/**
 * Describes the message llm.v2.GenerateTextRequest.
 * Use `create(GenerateTextRequestSchema)` to create a new message.
 */
export const GenerateTextRequestSchema: GenMessage<GenerateTextRequest> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 5);

/**
 * @generated from message llm.v2.GenerateTextResponse
 */
export type GenerateTextResponse = Message$1<"llm.v2.GenerateTextResponse"> & {
  /**
   * @generated from field: common.v2.Status status = 1;
   */
  status?: Status;

  /**
   * @generated from field: llm.v2.Message response_message = 2;
   */
  responseMessage?: Message;

  /**
   * @generated from field: repeated llm.v2.ToolCall tool_calls = 3;
   */
  toolCalls: ToolCall[];

  /**
   * @generated from field: optional llm.v2.TokenUsage usage = 4;
   */
  usage?: TokenUsage;

  /**
   * @generated from field: string finish_reason = 5;
   */
  finishReason: string;
};

/**
 * Describes the message llm.v2.GenerateTextResponse.
 * Use `create(GenerateTextResponseSchema)` to create a new message.
 */
export const GenerateTextResponseSchema: GenMessage<GenerateTextResponse> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 6);

/**
 * Request to generate text in a streaming fashion.
 *
 * @generated from message llm.v2.GenerateTextStreamRequest
 */
export type GenerateTextStreamRequest = Message$1<"llm.v2.GenerateTextStreamRequest"> & {
  /**
   * @generated from field: llm.v2.GenerateTextRequest request = 1;
   */
  request?: GenerateTextRequest;
};

/**
 * Describes the message llm.v2.GenerateTextStreamRequest.
 * Use `create(GenerateTextStreamRequestSchema)` to create a new message.
 */
export const GenerateTextStreamRequestSchema: GenMessage<GenerateTextStreamRequest> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 7);

/**
 * @generated from message llm.v2.GenerateTextStreamResponse
 */
export type GenerateTextStreamResponse = Message$1<"llm.v2.GenerateTextStreamResponse"> & {
  /**
   * @generated from field: common.v2.Status status = 1;
   */
  status?: Status;

  /**
   * @generated from field: string delta = 2;
   */
  delta: string;

  /**
   * @generated from field: optional llm.v2.TokenUsage usage = 3;
   */
  usage?: TokenUsage;

  /**
   * @generated from field: optional string finish_reason = 4;
   */
  finishReason?: string;

  /**
   * @generated from field: bool is_final = 5;
   */
  isFinal: boolean;
};

/**
 * Describes the message llm.v2.GenerateTextStreamResponse.
 * Use `create(GenerateTextStreamResponseSchema)` to create a new message.
 */
export const GenerateTextStreamResponseSchema: GenMessage<GenerateTextStreamResponse> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 8);

/**
 * @generated from message llm.v2.GenerateEmbeddingRequest
 */
export type GenerateEmbeddingRequest = Message$1<"llm.v2.GenerateEmbeddingRequest"> & {
  /**
   * @generated from field: llm.v2.Provider provider = 1;
   */
  provider: Provider;

  /**
   * @generated from field: string model = 2;
   */
  model: string;

  /**
   * @generated from field: repeated string texts = 3;
   */
  texts: string[];

  /**
   * @generated from field: common.v2.Metadata metadata = 4;
   */
  metadata?: Metadata;
};

/**
 * Describes the message llm.v2.GenerateEmbeddingRequest.
 * Use `create(GenerateEmbeddingRequestSchema)` to create a new message.
 */
export const GenerateEmbeddingRequestSchema: GenMessage<GenerateEmbeddingRequest> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 9);

/**
 * @generated from message llm.v2.Embedding
 */
export type Embedding = Message$1<"llm.v2.Embedding"> & {
  /**
   * @generated from field: repeated float values = 1;
   */
  values: number[];

  /**
   * @generated from field: int32 dimension = 2;
   */
  dimension: number;
};

/**
 * Describes the message llm.v2.Embedding.
 * Use `create(EmbeddingSchema)` to create a new message.
 */
export const EmbeddingSchema: GenMessage<Embedding> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 10);

/**
 * @generated from message llm.v2.GenerateEmbeddingResponse
 */
export type GenerateEmbeddingResponse = Message$1<"llm.v2.GenerateEmbeddingResponse"> & {
  /**
   * @generated from field: common.v2.Status status = 1;
   */
  status?: Status;

  /**
   * @generated from field: repeated llm.v2.Embedding embeddings = 2;
   */
  embeddings: Embedding[];

  /**
   * @generated from field: optional llm.v2.TokenUsage usage = 3;
   */
  usage?: TokenUsage;
};

/**
 * Describes the message llm.v2.GenerateEmbeddingResponse.
 * Use `create(GenerateEmbeddingResponseSchema)` to create a new message.
 */
export const GenerateEmbeddingResponseSchema: GenMessage<GenerateEmbeddingResponse> = /*@__PURE__*/
  messageDesc(file_llm_v2_llm, 11);

/**
 * @generated from enum llm.v2.Provider
 */
export enum Provider {
  /**
   * @generated from enum value: PROVIDER_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: PROVIDER_OPENAI = 1;
   */
  OPENAI = 1,

  /**
   * @generated from enum value: PROVIDER_ANTHROPIC = 2;
   */
  ANTHROPIC = 2,

  /**
   * @generated from enum value: PROVIDER_GOOGLE = 3;
   */
  GOOGLE = 3,

  /**
   * @generated from enum value: PROVIDER_AZURE_OPENAI = 4;
   */
  AZURE_OPENAI = 4,

  /**
   * @generated from enum value: PROVIDER_COHERE = 5;
   */
  COHERE = 5,

  /**
   * @generated from enum value: PROVIDER_OLLAMA = 6;
   */
  OLLAMA = 6,
}

/**
 * Describes the enum llm.v2.Provider.
 */
export const ProviderSchema: GenEnum<Provider> = /*@__PURE__*/
  enumDesc(file_llm_v2_llm, 0);

/**
 * @generated from enum llm.v2.MessageRole
 */
export enum MessageRole {
  /**
   * @generated from enum value: MESSAGE_ROLE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: MESSAGE_ROLE_SYSTEM = 1;
   */
  SYSTEM = 1,

  /**
   * @generated from enum value: MESSAGE_ROLE_USER = 2;
   */
  USER = 2,

  /**
   * @generated from enum value: MESSAGE_ROLE_ASSISTANT = 3;
   */
  ASSISTANT = 3,

  /**
   * @generated from enum value: MESSAGE_ROLE_TOOL = 4;
   */
  TOOL = 4,
}

/**
 * Describes the enum llm.v2.MessageRole.
 */
export const MessageRoleSchema: GenEnum<MessageRole> = /*@__PURE__*/
  enumDesc(file_llm_v2_llm, 1);

/**
 * @generated from service llm.v2.LLMProviderService
 */
export const LLMProviderService: GenService<{
  /**
   * @generated from rpc llm.v2.LLMProviderService.GenerateText
   */
  generateText: {
    methodKind: "unary";
    input: typeof GenerateTextRequestSchema;
    output: typeof GenerateTextResponseSchema;
  },
  /**
   * @generated from rpc llm.v2.LLMProviderService.GenerateTextStream
   */
  generateTextStream: {
    methodKind: "server_streaming";
    input: typeof GenerateTextStreamRequestSchema;
    output: typeof GenerateTextStreamResponseSchema;
  },
  /**
   * @generated from rpc llm.v2.LLMProviderService.GenerateEmbedding
   */
  generateEmbedding: {
    methodKind: "unary";
    input: typeof GenerateEmbeddingRequestSchema;
    output: typeof GenerateEmbeddingResponseSchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_llm_v2_llm, 0);

