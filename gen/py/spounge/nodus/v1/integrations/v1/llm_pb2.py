# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: nodus/v1/integrations/v1/llm.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""

from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder

_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC, 6, 31, 1, "", "nodus/v1/integrations/v1/llm.proto"
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n"nodus/v1/integrations/v1/llm.proto\x12\x18nodus.v1.integrations.v1\x1a\x1cgoogle/protobuf/struct.proto"\xdb\x04\n\x10LLMConfiguration\x12\x41\n\x08provider\x18\x01 \x01(\x0e\x32%.nodus.v1.integrations.v1.LLMProviderR\x08provider\x12\x1d\n\nmodel_name\x18\x02 \x01(\tR\tmodelName\x12#\n\rcredential_id\x18\x03 \x01(\tR\x0c\x63redentialId\x12\x19\n\x08\x62\x61se_url\x18\x04 \x01(\tR\x07\x62\x61seUrl\x12Q\n\x07headers\x18\x06 \x03(\x0b\x32\x37.nodus.v1.integrations.v1.LLMConfiguration.HeadersEntryR\x07headers\x12J\n\x0brate_limits\x18\x07 \x01(\x0b\x32).nodus.v1.integrations.v1.RateLimitConfigR\nrateLimits\x12m\n\x11provider_specific\x18\x08 \x03(\x0b\x32@.nodus.v1.integrations.v1.LLMConfiguration.ProviderSpecificEntryR\x10providerSpecific\x1a:\n\x0cHeadersEntry\x12\x10\n\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n\x05value\x18\x02 \x01(\tR\x05value:\x02\x38\x01\x1a[\n\x15ProviderSpecificEntry\x12\x10\n\x03key\x18\x01 \x01(\tR\x03key\x12,\n\x05value\x18\x02 \x01(\x0b\x32\x16.google.protobuf.ValueR\x05value:\x02\x38\x01"\xaf\x02\n\rLLMParameters\x12 \n\x0btemperature\x18\x01 \x01(\x02R\x0btemperature\x12\x1d\n\nmax_tokens\x18\x02 \x01(\x05R\tmaxTokens\x12\x13\n\x05top_p\x18\x03 \x01(\x02R\x04topP\x12\x13\n\x05top_k\x18\x04 \x01(\x02R\x04topK\x12+\n\x11\x66requency_penalty\x18\x05 \x01(\x02R\x10\x66requencyPenalty\x12)\n\x10presence_penalty\x18\x06 \x01(\x02R\x0fpresencePenalty\x12%\n\x0estop_sequences\x18\x07 \x03(\tR\rstopSequences\x12\x34\n\x16system_prompt_template\x18\x08 \x01(\tR\x14systemPromptTemplate"\x9e\x01\n\x0fRateLimitConfig\x12.\n\x13requests_per_minute\x18\x01 \x01(\x05R\x11requestsPerMinute\x12*\n\x11tokens_per_minute\x18\x02 \x01(\x05R\x0ftokensPerMinute\x12/\n\x13\x63oncurrent_requests\x18\x03 \x01(\x05R\x12\x63oncurrentRequests*\xa7\x02\n\x0bLLMProvider\x12\x1c\n\x18LLM_PROVIDER_UNSPECIFIED\x10\x00\x12\x17\n\x13LLM_PROVIDER_OPENAI\x10\x01\x12\x1a\n\x16LLM_PROVIDER_ANTHROPIC\x10\x02\x12\x17\n\x13LLM_PROVIDER_COHERE\x10\x03\x12\x1d\n\x19LLM_PROVIDER_HUGGING_FACE\x10\x04\x12\x17\n\x13LLM_PROVIDER_GOOGLE\x10\x05\x12\x18\n\x14LLM_PROVIDER_MISTRAL\x10\x06\x12\x1d\n\x19LLM_PROVIDER_LOCAL_OLLAMA\x10\x07\x12\x1d\n\x19LLM_PROVIDER_AZURE_OPENAI\x10\x08\x12\x1c\n\x18LLM_PROVIDER_AWS_BEDROCK\x10\tB\xff\x01\n\x1c\x63om.nodus.v1.integrations.v1B\x08LlmProtoP\x01ZRgithub.com/spounge-ai/spounge-proto/gen/go/nodus/v1/integrations/v1;integrationsv1\xa2\x02\x03NVI\xaa\x02\x18Nodus.V1.Integrations.V1\xca\x02\x18Nodus\\V1\\Integrations\\V1\xe2\x02$Nodus\\V1\\Integrations\\V1\\GPBMetadata\xea\x02\x1bNodus::V1::Integrations::V1b\x06proto3'
)

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(
    DESCRIPTOR, "nodus.v1.integrations.v1.llm_pb2", _globals
)
if not _descriptor._USE_C_DESCRIPTORS:
    _globals["DESCRIPTOR"]._loaded_options = None
    _globals[
        "DESCRIPTOR"
    ]._serialized_options = b"\n\034com.nodus.v1.integrations.v1B\010LlmProtoP\001ZRgithub.com/spounge-ai/spounge-proto/gen/go/nodus/v1/integrations/v1;integrationsv1\242\002\003NVI\252\002\030Nodus.V1.Integrations.V1\312\002\030Nodus\\V1\\Integrations\\V1\342\002$Nodus\\V1\\Integrations\\V1\\GPBMetadata\352\002\033Nodus::V1::Integrations::V1"
    _globals["_LLMCONFIGURATION_HEADERSENTRY"]._loaded_options = None
    _globals["_LLMCONFIGURATION_HEADERSENTRY"]._serialized_options = b"8\001"
    _globals["_LLMCONFIGURATION_PROVIDERSPECIFICENTRY"]._loaded_options = None
    _globals["_LLMCONFIGURATION_PROVIDERSPECIFICENTRY"]._serialized_options = b"8\001"
    _globals["_LLMPROVIDER"]._serialized_start = 1168
    _globals["_LLMPROVIDER"]._serialized_end = 1463
    _globals["_LLMCONFIGURATION"]._serialized_start = 95
    _globals["_LLMCONFIGURATION"]._serialized_end = 698
    _globals["_LLMCONFIGURATION_HEADERSENTRY"]._serialized_start = 547
    _globals["_LLMCONFIGURATION_HEADERSENTRY"]._serialized_end = 605
    _globals["_LLMCONFIGURATION_PROVIDERSPECIFICENTRY"]._serialized_start = 607
    _globals["_LLMCONFIGURATION_PROVIDERSPECIFICENTRY"]._serialized_end = 698
    _globals["_LLMPARAMETERS"]._serialized_start = 701
    _globals["_LLMPARAMETERS"]._serialized_end = 1004
    _globals["_RATELIMITCONFIG"]._serialized_start = 1007
    _globals["_RATELIMITCONFIG"]._serialized_end = 1165
# @@protoc_insertion_point(module_scope)
